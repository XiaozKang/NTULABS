{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(74, 348)\n",
       "    (wpe): Embedding(256, 348)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=348, out_features=1044, bias=False)\n",
       "          (c_proj): Linear(in_features=348, out_features=348, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=348, out_features=1392, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1392, out_features=348, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=348, out_features=74, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b04f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated and saved 100000 math problems to ./pos_neg_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# Generating 100000 positive and negative pairs\n",
    "problems = []\n",
    "noOfQuestions = 100000\n",
    "valueLimit = 200\n",
    "\n",
    "# Helper functions\n",
    "def add_problem(question, answer, reason):\n",
    "    problems.append({\n",
    "        \"negative\": f\"{question} Sorry, I do not know\",\n",
    "        \"positive\": f\"{question} The answer is {answer} because {reason}.\"\n",
    "    })\n",
    "\n",
    "for i in range(0, noOfQuestions):\n",
    "    qntype = random.randint(1, 2) # 1: arithmetic, 2: one-step\n",
    "\n",
    "    if qntype == 1: # arithmetic\n",
    "        # Random addition/subtraction/multiplication\n",
    "        operation = random.choice(['+', '-', '*', '/'])\n",
    "        if operation == '+':\n",
    "            a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "            answer = a + b\n",
    "            add_problem(f\"{a}+{b}=?\", answer, f\"{a}+{b} equals {answer}\")\n",
    "        elif operation == '-':\n",
    "            a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "            answer = a - b\n",
    "            add_problem(f\"{a}-{b}=?\", answer, f\"{a}-{b} equals {answer}\")\n",
    "        elif operation == '*':  # multiplication\n",
    "            a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "            answer = a * b\n",
    "            add_problem(f\"{a}*{b}=?\", answer, f\"{a}*{b} equals {answer}\")\n",
    "        else:  # division\n",
    "            b = random.randint(1, valueLimit)\n",
    "            answer = random.randint(0, valueLimit)\n",
    "            a = b * answer  # Ensure a is divisible by b\n",
    "            add_problem(f\"{a}/{b}=?\", answer, f\"{a}/{b} equals {answer}\")\n",
    "    elif qntype == 2: # one-step equations\n",
    "        positiontype = random.choice(['x_first', 'x_second'])\n",
    "        operation = random.choice(['add', 'subtract', 'multiply', 'divide'])\n",
    "        if operation == 'add':\n",
    "            a,b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "            x = a - b\n",
    "            if positiontype == 'x_first':\n",
    "                add_problem(f\"x+{b}={a},x=?\", x, f\"{a}-{b} equals {x}\")\n",
    "            else:\n",
    "                add_problem(f\"{b}+x={a},x=?\", x, f\"{a}-{b} equals {x}\")\n",
    "        elif operation == 'subtract':\n",
    "            a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "            if positiontype == 'x_first':\n",
    "                x = a + b\n",
    "                add_problem(f\"x-{a}={b},x=?\", x, f\"{b}+{a} equals {x}\")\n",
    "            else:\n",
    "                x = a - b\n",
    "                add_problem(f\"{a}-x={b},x=?\", x, f\"{a}-{b} equals {x}\")\n",
    "        elif operation == 'multiply':\n",
    "            a = random.randint(1, valueLimit)\n",
    "            x = random.randint(0, valueLimit)\n",
    "            b = a * x\n",
    "            if positiontype == 'x_first':\n",
    "                add_problem(f\"x*{a}={b},x=?\", x, f\"{b}/{a} equals {x}\")\n",
    "            else:\n",
    "                add_problem(f\"{a}*x={b},x=?\", x, f\"{b}/{a} equals {x}\")\n",
    "        else:  # divide\n",
    "            if positiontype == 'x_first':\n",
    "                a= random.randint(1, valueLimit)\n",
    "                b = random.randint(0, valueLimit)\n",
    "                x = a * b\n",
    "                add_problem(f\"x/{a}={b},x=?\", x, f\"{b}*{a} equals {x}\")\n",
    "            else:\n",
    "                a = random.randint(1, valueLimit)\n",
    "                x = random.randint(1, valueLimit)\n",
    "                b = a * x\n",
    "                add_problem(f\"{b}/x={a},x=?\", x, f\"{b}/{a} equals {x}\")\n",
    "\n",
    "# Save as JSON file\n",
    "file_path = \"./pos_neg_pairs.json\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(problems, f, indent=2)\n",
    "\n",
    "print(f\"Generated and saved {len(problems)} math problems to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f292a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 preference pairs\n"
     ]
    }
   ],
   "source": [
    "with open(\"pos_neg_pairs.json\", \"r\") as f:\n",
    "    lines = json.load(f)\n",
    "print(f\"Loaded {len(lines)} preference pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer and scheduler created\n"
     ]
    }
   ],
   "source": [
    "# Recommend to use the AdamW optimizer with learning rate scheduling\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=base_lr, weight_decay=1e-4)\n",
    "\n",
    "# Add learning rate scheduler for better convergence, so that it decreases when loss plateaus, after 2 epochs. we half the learning rate\n",
    "# Ensures we dont overshoot when loss is low\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "print(\"Optimizer and scheduler created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4ebeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.034221574664115906, DPO: 0.0006775043439120054, Beta: 0.3373575197072858: : 1562it [01:17, 20.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average loss: 0.06620864666731271\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.027805885300040245, DPO: 0.00034961511846631765, Beta: 0.262890294067124: : 1562it [01:21, 19.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average loss: 0.03031804961022395\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.027318811044096947, DPO: 0.00014017544162925333, Beta: 0.22879484935573954: : 1562it [01:23, 18.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Average loss: 0.027659340631622207\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.02561693824827671, DPO: 4.4910037104273215e-05, Beta: 0.2131839636261651: : 1562it [01:19, 19.53it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Average loss: 0.026363100435599092\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.02478841319680214, DPO: 1.960662666533608e-05, Beta: 0.20603638847867015: : 1562it [01:19, 19.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Average loss: 0.025221520363473634\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.023259012028574944, DPO: 1.0296986147295684e-05, Beta: 0.20276381116473255: : 1562it [01:21, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Average loss: 0.023905210856410286\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.022050272673368454, DPO: 5.49074911759817e-06, Beta: 0.20126543415508985: : 1562it [01:17, 20.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Average loss: 0.022763674706697618\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.021381568163633347, DPO: 2.891529447879293e-06, Beta: 0.2005793896563197: : 1562it [01:19, 19.69it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Average loss: 0.02177371589106802\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.02039012312889099, DPO: 2.265616785734892e-06, Beta: 0.2002652784204537: : 1562it [01:23, 18.65it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Average loss: 0.021211511857340187\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.020627615973353386, DPO: 1.333976683781657e-06, Beta: 0.2001214599528848: : 1562it [01:22, 18.97it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Average loss: 0.020769786226793305\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.020580662414431572, DPO: 9.265318681173085e-07, Beta: 0.20005561145957293: : 1562it [01:17, 20.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed. Average loss: 0.020462165635541825\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.019980600103735924, DPO: 8.902433137336629e-07, Beta: 0.2000254621738473: : 1562it [01:23, 18.65it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed. Average loss: 0.02022726452467002\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.01952001266181469, DPO: 3.798129171173059e-07, Beta: 0.20001165807015361: : 1562it [01:23, 18.64it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed. Average loss: 0.020040546263664694\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.02046428993344307, DPO: 4.153253598815354e-07, Beta: 0.20000533774533596: : 1562it [01:19, 19.68it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed. Average loss: 0.019868801216739163\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.020321952179074287, DPO: 4.5081020516590797e-07, Beta: 0.20000244393153388: : 1562it [01:19, 19.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed. Average loss: 0.019746864048785576\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.019875802099704742, DPO: 2.2503732566292456e-07, Beta: 0.20000111897457937: : 1562it [01:19, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed. Average loss: 0.01961574962221935\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.01872440241277218, DPO: 2.2296832469237415e-07, Beta: 0.20000051233190916: : 1562it [01:18, 19.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed. Average loss: 0.019523449416216296\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.019371455535292625, DPO: 1.8131837009605078e-07, Beta: 0.2000002345754673: : 1562it [01:21, 19.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed. Average loss: 0.019419543712224607\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.01927771233022213, DPO: 1.7547142761031864e-07, Beta: 0.20000010740234825: : 1562it [01:20, 19.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed. Average loss: 0.019335241023589418\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.019306903705000877, DPO: 1.4361926048422902e-07, Beta: 0.20000004917506733: : 1562it [01:20, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed. Average loss: 0.019246213600783588\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.019408229738473892, DPO: 1.3823351707742404e-07, Beta: 0.20000002251521765: : 1562it [01:21, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed. Average loss: 0.019174425322538605\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.01846139319241047, DPO: 1.196039107753677e-07, Beta: 0.20000001030878162: : 1562it [01:22, 18.99it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed. Average loss: 0.01910837094696589\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.018807264044880867, DPO: 1.2946331651164655e-07, Beta: 0.20000000471996243: : 1562it [01:21, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed. Average loss: 0.01904406097554214\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.019068753346800804, DPO: 9.288483937552883e-08, Beta: 0.20000000216107514: : 1562it [01:19, 19.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed. Average loss: 0.018977259012671346\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.018647020682692528, DPO: 1.01405291275114e-07, Beta: 0.20000000098946616: : 1562it [01:20, 19.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed. Average loss: 0.018917183730412613\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.01899535395205021, DPO: 8.209839563733112e-08, Beta: 0.200000000453035: : 1562it [01:20, 19.37it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed. Average loss: 0.01885778078554191\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.018181294202804565, DPO: 9.787794397198013e-08, Beta: 0.2000000002074256: : 1562it [01:20, 19.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed. Average loss: 0.01879262562278329\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.018485134467482567, DPO: 9.74126166397582e-08, Beta: 0.20000000009497143: : 1562it [01:19, 19.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed. Average loss: 0.01874003720573518\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.01849723421037197, DPO: 1.0085742019327881e-07, Beta: 0.2000000000434836: : 1562it [01:22, 19.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed. Average loss: 0.018687005553074974\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.018622037023305893, DPO: 1.086011636175499e-07, Beta: 0.20000000001990934: : 1562it [01:22, 18.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed. Average loss: 0.018628219513415756\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.01894625462591648, DPO: 9.73414771010539e-08, Beta: 0.20000000000911566: : 1562it [01:23, 18.79it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed. Average loss: 0.01858749388265167\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.018293017521500587, DPO: 8.059713252350775e-08, Beta: 0.20000000000417378: : 1562it [01:16, 20.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed. Average loss: 0.0185402518486492\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.01804746873676777, DPO: 6.636356886247086e-08, Beta: 0.20000000000191098: : 1562it [01:19, 19.60it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed. Average loss: 0.018488577587312986\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.018148336559534073, DPO: 7.927842204935587e-08, Beta: 0.20000000000087512: : 1562it [01:25, 18.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed. Average loss: 0.018452976882772545\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.018511421978473663, DPO: 8.552167685138556e-08, Beta: 0.20000000000040105: : 1562it [01:20, 19.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed. Average loss: 0.01840075301113759\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.018252257257699966, DPO: 6.341988978419977e-08, Beta: 0.2000000000001841: : 1562it [01:19, 19.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed. Average loss: 0.018352236932622945\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.018261732533574104, DPO: 5.928996671400455e-08, Beta: 0.20000000000008275: : 1562it [01:20, 19.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed. Average loss: 0.01832993739975018\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.018235012888908386, DPO: 6.652955164554442e-08, Beta: 0.2000000000000394: : 1562it [01:21, 19.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed. Average loss: 0.018274115771770707\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.018412133678793907, DPO: 5.5538698973123246e-08, Beta: 0.20000000000002774: : 1562it [01:13, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed. Average loss: 0.018232460115844246\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.01799737475812435, DPO: 8.466250278615917e-08, Beta: 0.20000000000002774: : 1562it [01:24, 18.42it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed. Average loss: 0.018199431577580534\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.01815987005829811, DPO: 4.961067645581352e-08, Beta: 0.20000000000002774: : 1562it [01:23, 18.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed. Average loss: 0.018152353740160124\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.017900221049785614, DPO: 5.4313989750198743e-08, Beta: 0.20000000000002774: : 1562it [01:20, 19.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed. Average loss: 0.01812588295657259\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.017938340082764626, DPO: 5.988037798942969e-08, Beta: 0.20000000000002774: : 1562it [01:21, 19.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed. Average loss: 0.01807901783752113\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.018006112426519394, DPO: 8.111572924462962e-08, Beta: 0.20000000000002774: : 1562it [01:18, 19.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed. Average loss: 0.01803400197809278\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.018291914835572243, DPO: 5.528772462071174e-08, Beta: 0.20000000000002774: : 1562it [01:24, 18.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed. Average loss: 0.017997261239323055\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.01797499507665634, DPO: 9.870497308384074e-08, Beta: 0.20000000000002774: : 1562it [01:19, 19.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed. Average loss: 0.017963688765746683\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.018127387389540672, DPO: 6.122949969267211e-08, Beta: 0.20000000000002774: : 1562it [01:22, 19.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed. Average loss: 0.017922255181959054\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.017972629517316818, DPO: 3.88161573994239e-08, Beta: 0.20000000000002774: : 1562it [01:20, 19.36it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed. Average loss: 0.017884918093853053\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.018225526437163353, DPO: 3.6294238725531613e-08, Beta: 0.20000000000002774: : 1562it [01:24, 18.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed. Average loss: 0.017856220533491785\n",
      "New best model saved to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.017587006092071533, DPO: 4.183582547057085e-08, Beta: 0.20000000000002774: : 1562it [01:19, 19.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed. Average loss: 0.017809806092285697\n",
      "New best model saved to ./dpo.pt\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "\n",
    "# Dynamic beta, so that we prefer positive samples first to help learn better\n",
    "# then gradually reduce beta to help fine tune and not force positive samples too much\n",
    "final_beta = 0.2 # Our final beta value\n",
    "current_beta = beta\n",
    "\n",
    "# Loss tracking per epoch for plotting in next cell\n",
    "epoch_loss_arr = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    epoch_losses = []\n",
    "    for step, (neg_tensor, pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Update beta dynamically for each step (instead of once per epoch) so its smoother\n",
    "        # Extra computation is negligible compared to the benefit\n",
    "        # Used exponential decay like epsilon soft policy\n",
    "        current_beta = current_beta * 0.9995 + final_beta * 0.0005\n",
    "\n",
    "        optimizer.zero_grad() # Clear gradients before each step\n",
    "        \n",
    "        # Compute log probabilities for negative and positive responses using the helper function\n",
    "        neg_logprob = compute_logprob(neg_tensor)\n",
    "        pos_logprob = compute_logprob(pos_tensor)\n",
    "        \n",
    "        # Encourage the model to assign higher probability to positive answers\n",
    "        # Use policy gradient technique where we reward good answers over bad\n",
    "        r = (pos_logprob - neg_logprob) / temperature\n",
    "        weighted_diff = current_beta * r # Add in our beta effect\n",
    "        # Use example code from given template\n",
    "        dpo_loss = -F.logsigmoid(weighted_diff).mean()\n",
    "        \n",
    "        # Encourage it to prefer the positive samples so we dont forget our old knowledge\n",
    "        constant = (-pos_logprob).mean() * 0.08\n",
    "        \n",
    "        # Combine the losses for a combined training\n",
    "        combined_loss = dpo_loss + constant\n",
    "\n",
    "        # Discard step if loss is problematic\n",
    "        if torch.isnan(combined_loss) or torch.isinf(combined_loss): continue\n",
    "\n",
    "        # Computing gradients\n",
    "        combined_loss.backward()\n",
    "        # Clipping gradients to avoid explosion, that cause learning divergence\n",
    "        torch.nn.utils.clip_grad_norm_(gpt.parameters(), max_norm=5.0) # Cap it at 5.0\n",
    "        optimizer.step() # Update parameters of the model\n",
    "        \n",
    "        # Track loss for each step in this epoch\n",
    "        epoch_losses.append(combined_loss.item())\n",
    "\n",
    "        pbar.set_description(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \", Loss: \" + str(combined_loss.item()) + \", DPO: \" + str(dpo_loss.item()) + \", Beta: \" + str(current_beta))\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    epoch_loss_arr.append(avg_loss) # Add to array for plotting later\n",
    "\n",
    "    # Feed scheduler with the average loss (our epoch's performance) \n",
    "    # for it to see when to reduce learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "    print(\"Epoch \" + str(epoch+1) + \" completed. Average loss: \" + str(avg_loss))\n",
    "    \n",
    "    # Save checkpoint (save best model only), so we dont save a worse model\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        ckpt_path = \"./dpo.pt\"\n",
    "        torch.save({\n",
    "            \"model_state_dict\": gpt.state_dict(),\n",
    "            \"model_args\": ckpt['model_args'],\n",
    "        }, ckpt_path)\n",
    "        print(\"New best model saved to \" + ckpt_path)\n",
    "\n",
    "print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7ba311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss against number of epochs graph\n",
    "fit = plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1, len(epoch_loss_arr) + 1), epoch_loss_arr, color='b', label='Training Loss', marker='o')\n",
    "# Marking minimum loss epoch\n",
    "minposs = epoch_loss_arr.index(min(epoch_loss_arr))+1\n",
    "plt.axvline(minposs, linestyle='--', color='r', label='Minimum Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09027262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: 17+19=?\n",
      "Response: 17+19=? The answer is 36 because 17+19 equals 36.\n",
      "\n",
      "Prompt: 3*17=?\n",
      "Response: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "\n",
      "Prompt: 72/4=?\n",
      "Response: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "\n",
      "Prompt: 72-x=34,x=?\n",
      "Response: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "\n",
      "Prompt: x*11=44,x=?\n",
      "Response: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "\n",
      "Prompt: 3*17=?\n",
      "Response: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "\n",
      "Prompt: 72/4=?\n",
      "Response: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "\n",
      "Prompt: 72-x=34,x=?\n",
      "Response: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"./dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).to(device)\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "\n",
    "# Test the model\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "\n",
    "# Making sure gradients will not be computed and updated\n",
    "with torch.no_grad():\n",
    "\n",
    "    for prompt in test_set: \n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        prompt_ids = encode(prompt)\n",
    "        x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "        \n",
    "        # Generate response using the fine-tuned model\n",
    "        # Note: generate() returns (generated_sequence, hidden_states)\n",
    "        generated_seq, _ = gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        \n",
    "        # Extract the generated sequence properly\n",
    "        generated_ids = generated_seq[0].cpu().tolist()  # Move to CPU and convert to list\n",
    "            \n",
    "        response = decode(generated_ids)\n",
    "        print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b8670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 13: : 0it [00:02, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 42*84=? The answer is 3448 because 42*84 equals 3448.\n",
      "Expected Answer: The answer is 3528 because 42*84 equals 3528.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 16: : 0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 67*34=? The answer is 2218 because 67*34 equals 2218.\n",
      "Expected Answer: The answer is 2278 because 67*34 equals 2278.\n",
      "Incorrect\n",
      "Response: x*75=4575,x=? The answer is 59 because 4575/75 equals 59.\n",
      "Expected Answer: The answer is 61 because 4575/75 equals 61.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 18: : 0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 396/4=? The answer is 94 because 396/4 equals 94.\n",
      "Expected Answer: The answer is 99 because 396/4 equals 99.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 33: : 0it [00:05, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 94*83=? The answer is 7702 because 94*83 equals 7702.\n",
      "Expected Answer: The answer is 7802 because 94*83 equals 7802.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 68: : 0it [00:11, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 23*73=? The answer is 1619 because 23*73 equals 1619.\n",
      "Expected Answer: The answer is 1679 because 23*73 equals 1679.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 80: : 0it [00:13, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 80*x=3120,x=? The answer is 44 because 3120/80 equals 44.\n",
      "Expected Answer: The answer is 39 because 3120/80 equals 39.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 82: : 0it [00:13, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 81*48=? The answer is 3988 because 81*48 equals 3988.\n",
      "Expected Answer: The answer is 3888 because 81*48 equals 3888.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 87: : 0it [00:14, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/85=51,x=? The answer is 4235 because 51*85 equals 4235.\n",
      "Expected Answer: The answer is 4335 because 51*85 equals 4335.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 105: : 0it [00:17, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 3827/43=? The answer is 99 because 3827/43 equals 99.\n",
      "Expected Answer: The answer is 89 because 3827/43 equals 89.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 115: : 0it [00:19, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 78*68=? The answer is 5344 because 78*68 equals 5344.\n",
      "Expected Answer: The answer is 5304 because 78*68 equals 5304.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 122: : 0it [00:20, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 86*32=? The answer is 2712 because 86*32 equals 2712.\n",
      "Expected Answer: The answer is 2752 because 86*32 equals 2752.\n",
      "Incorrect\n",
      "Response: 6825/x=75,x=? The answer is 99 because 6825/75 equals 99.\n",
      "Expected Answer: The answer is 91 because 6825/75 equals 91.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 142: : 0it [00:23, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/36=43,x=? The answer is 1508 because 43*36 equals 1508.\n",
      "Expected Answer: The answer is 1548 because 43*36 equals 1548.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 149: : 0it [00:24, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 6630/x=85,x=? The answer is 198 because 16630/85 equals 198.\n",
      "Expected Answer: The answer is 78 because 6630/85 equals 78.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 162: : 0it [00:27, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 82*85=? The answer is 6870 because 82*85 equals 6870.\n",
      "Expected Answer: The answer is 6970 because 82*85 equals 6970.\n",
      "Incorrect\n",
      "Response: 55*92=? The answer is 5960 because 55*92 equals 5960.\n",
      "Expected Answer: The answer is 5060 because 55*92 equals 5060.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 166: : 0it [00:27, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1691/x=89,x=? The answer is 139 because 11691/89 equals 139.\n",
      "Expected Answer: The answer is 19 because 1691/89 equals 19.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 168: : 0it [00:28, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 89*59=? The answer is 5171 because 89*59 equals 5171.\n",
      "Expected Answer: The answer is 5251 because 89*59 equals 5251.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 170: : 0it [00:28, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1080/12=? The answer is 80 because 1080/12 equals 80.\n",
      "Expected Answer: The answer is 90 because 1080/12 equals 90.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 172: : 0it [00:28, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 66*39=? The answer is 2594 because 66*39 equals 2594.\n",
      "Expected Answer: The answer is 2574 because 66*39 equals 2574.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 188: : 0it [00:31, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 68*74=? The answer is 5912 because 68*74 equals 5912.\n",
      "Expected Answer: The answer is 5032 because 68*74 equals 5032.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 204: : 0it [00:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x*72=2808,x=? The answer is 34 because 2808/72 equals 34.\n",
      "Expected Answer: The answer is 39 because 2808/72 equals 39.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 208: : 0it [00:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 41*39=? The answer is 1519 because 41*39 equals 1519.\n",
      "Expected Answer: The answer is 1599 because 41*39 equals 1599.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 229: : 0it [00:38, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1615/x=85,x=? The answer is 131 because 11615/85 equals 131.\n",
      "Expected Answer: The answer is 19 because 1615/85 equals 19.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 235: : 0it [00:39, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 30*54=? The answer is 1520 because 30*54 equals 1520.\n",
      "Expected Answer: The answer is 1620 because 30*54 equals 1620.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 252: : 0it [00:42, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 57*56=? The answer is 3232 because 57*56 equals 3232.\n",
      "Expected Answer: The answer is 3192 because 57*56 equals 3192.\n",
      "Incorrect\n",
      "Response: 1408/44=? The answer is 37 because 1408/44 equals 37.\n",
      "Expected Answer: The answer is 32 because 1408/44 equals 32.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 257: : 0it [00:42, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 26*44=? The answer is 1024 because 26*44 equals 1024.\n",
      "Expected Answer: The answer is 1144 because 26*44 equals 1144.\n",
      "Incorrect\n",
      "Response: x/37=66,x=? The answer is 2522 because 66*37 equals 2522.\n",
      "Expected Answer: The answer is 2442 because 66*37 equals 2442.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 281: : 0it [00:46, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 83*91=? The answer is 7653 because 83*91 equals 7653.\n",
      "Expected Answer: The answer is 7553 because 83*91 equals 7553.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 299: : 0it [00:49, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5600/80=? The answer is 65 because 5600/80 equals 65.\n",
      "Expected Answer: The answer is 70 because 5600/80 equals 70.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 314: : 0it [00:52, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1386/x=66,x=? The answer is 171 because 11386/66 equals 171.\n",
      "Expected Answer: The answer is 21 because 1386/66 equals 21.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 324: : 0it [00:53, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5336/58=? The answer is 82 because 5336/58 equals 82.\n",
      "Expected Answer: The answer is 92 because 5336/58 equals 92.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 331: : 0it [00:55, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 6030/x=67,x=? The answer is 80 because 6030/67 equals 80.\n",
      "Expected Answer: The answer is 90 because 6030/67 equals 90.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 337: : 0it [00:56, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/37=32,x=? The answer is 1244 because 32*37 equals 1244.\n",
      "Expected Answer: The answer is 1184 because 32*37 equals 1184.\n",
      "Incorrect\n",
      "Response: 60*49=? The answer is 3140 because 60*49 equals 3140.\n",
      "Expected Answer: The answer is 2940 because 60*49 equals 2940.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 339: : 0it [00:56, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 49*37=? The answer is 1873 because 49*37 equals 1873.\n",
      "Expected Answer: The answer is 1813 because 49*37 equals 1813.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 345: : 0it [00:57, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 52*97=? The answer is 4984 because 52*97 equals 4984.\n",
      "Expected Answer: The answer is 5044 because 52*97 equals 5044.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 355: : 0it [00:58, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1806/x=21,x=? The answer is 96 because 1806/21 equals 96.\n",
      "Expected Answer: The answer is 86 because 1806/21 equals 86.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 385: : 0it [01:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 35*92=? The answer is 3120 because 35*92 equals 3120.\n",
      "Expected Answer: The answer is 3220 because 35*92 equals 3220.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 390: : 0it [01:04, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1586/x=61,x=? The answer is 196 because 11586/61 equals 196.\n",
      "Expected Answer: The answer is 26 because 1586/61 equals 26.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 408: : 0it [01:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/56=88,x=? The answer is 4968 because 88*56 equals 4968.\n",
      "Expected Answer: The answer is 4928 because 88*56 equals 4928.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 436: : 0it [01:11, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/39=37,x=? The answer is 1403 because 37*39 equals 1403.\n",
      "Expected Answer: The answer is 1443 because 37*39 equals 1443.\n",
      "Incorrect\n",
      "Response: 74*79=? The answer is 5706 because 74*79 equals 5706.\n",
      "Expected Answer: The answer is 5846 because 74*79 equals 5846.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 455: : 0it [01:14, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 17*64=? The answer is 1128 because 17*64 equals 1128.\n",
      "Expected Answer: The answer is 1088 because 17*64 equals 1088.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 459: : 0it [01:15, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/28=89,x=? The answer is 2572 because 89*28 equals 2572.\n",
      "Expected Answer: The answer is 2492 because 89*28 equals 2492.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 464: : 0it [01:16, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1265/x=55,x=? The answer is 27 because 1265/55 equals 27.\n",
      "Expected Answer: The answer is 23 because 1265/55 equals 23.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 222: : 0it [01:20, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 3024/x=36,x=? The answer is 89 because 3024/36 equals 89.\n",
      "Expected Answer: The answer is 84 because 3024/36 equals 84.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 494: : 0it [01:20, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/40=17,x=? The answer is 780 because 17*40 equals 780.\n",
      "Expected Answer: The answer is 680 because 17*40 equals 680.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 513: : 0it [01:23, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 37*89=? The answer is 3393 because 37*89 equals 3393.\n",
      "Expected Answer: The answer is 3293 because 37*89 equals 3293.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 515: : 0it [01:24, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/64=24,x=? The answer is 1456 because 24*64 equals 1456.\n",
      "Expected Answer: The answer is 1536 because 24*64 equals 1536.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 522: : 0it [01:25, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/76=38,x=? The answer is 3848 because 38*76 equals 3848.\n",
      "Expected Answer: The answer is 2888 because 38*76 equals 2888.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 528: : 0it [01:26, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 28*82=? The answer is 2376 because 28*82 equals 2376.\n",
      "Expected Answer: The answer is 2296 because 28*82 equals 2296.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 533: : 0it [01:27, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 3354/x=78,x=? The answer is 163 because 13354/78 equals 163.\n",
      "Expected Answer: The answer is 43 because 3354/78 equals 43.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 543: : 0it [01:28, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 2624/64=? The answer is 46 because 2624/64 equals 46.\n",
      "Expected Answer: The answer is 41 because 2624/64 equals 41.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 545: : 0it [01:28, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 4050/x=90,x=? The answer is 155 because 14050/90 equals 155.\n",
      "Expected Answer: The answer is 45 because 4050/90 equals 45.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 557: : 0it [01:30, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/43=18,x=? The answer is 794 because 18*43 equals 794.\n",
      "Expected Answer: The answer is 774 because 18*43 equals 774.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 559: : 0it [01:31, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 41*43=? The answer is 1803 because 41*43 equals 1803.\n",
      "Expected Answer: The answer is 1763 because 41*43 equals 1763.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 581: : 0it [01:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 72*94=? The answer is 6728 because 72*94 equals 6728.\n",
      "Expected Answer: The answer is 6768 because 72*94 equals 6768.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 585: : 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 56*33=? The answer is 1868 because 56*33 equals 1868.\n",
      "Expected Answer: The answer is 1848 because 56*33 equals 1848.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 595: : 0it [01:36, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1980/x=60,x=? The answer is 193 because 11980/60 equals 193.\n",
      "Expected Answer: The answer is 33 because 1980/60 equals 33.\n",
      "Incorrect\n",
      "Response: 86*35=? The answer is 3110 because 86*35 equals 3110.\n",
      "Expected Answer: The answer is 3010 because 86*35 equals 3010.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 599: : 0it [01:37, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x*75=5625,x=? The answer is 73 because 5625/75 equals 73.\n",
      "Expected Answer: The answer is 75 because 5625/75 equals 75.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 630: : 0it [01:42, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 92*27=? The answer is 2524 because 92*27 equals 2524.\n",
      "Expected Answer: The answer is 2484 because 92*27 equals 2484.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 633: : 0it [01:43, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 78*53=? The answer is 4074 because 78*53 equals 4074.\n",
      "Expected Answer: The answer is 4134 because 78*53 equals 4134.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 643: : 0it [01:44, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x*62=5580,x=? The answer is 85 because 5580/62 equals 85.\n",
      "Expected Answer: The answer is 90 because 5580/62 equals 90.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 648: : 0it [01:45, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 66*73=? The answer is 4778 because 66*73 equals 4778.\n",
      "Expected Answer: The answer is 4818 because 66*73 equals 4818.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 669: : 0it [01:48, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 8*88=? The answer is 604 because 8*88 equals 604.\n",
      "Expected Answer: The answer is 704 because 8*88 equals 704.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 675: : 0it [01:49, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/77=46,x=? The answer is 3682 because 46*77 equals 3682.\n",
      "Expected Answer: The answer is 3542 because 46*77 equals 3542.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 705: : 0it [01:54, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 75*96=? The answer is 7100 because 75*96 equals 7100.\n",
      "Expected Answer: The answer is 7200 because 75*96 equals 7200.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 711: : 0it [01:55, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5092/76=? The answer is 62 because 5092/76 equals 62.\n",
      "Expected Answer: The answer is 67 because 5092/76 equals 67.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 721: : 0it [01:57, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 29*26=? The answer is 734 because 29*26 equals 734.\n",
      "Expected Answer: The answer is 754 because 29*26 equals 754.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 730: : 0it [01:58, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5963/x=89,x=? The answer is 177 because 15963/89 equals 177.\n",
      "Expected Answer: The answer is 67 because 5963/89 equals 67.\n",
      "Incorrect\n",
      "Response: 34*16=? The answer is 504 because 34*16 equals 504.\n",
      "Expected Answer: The answer is 544 because 34*16 equals 544.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 753: : 0it [02:02, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 13*92=? The answer is 1116 because 13*92 equals 1116.\n",
      "Expected Answer: The answer is 1196 because 13*92 equals 1196.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 758: : 0it [02:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/65=65,x=? The answer is 4125 because 65*65 equals 4125.\n",
      "Expected Answer: The answer is 4225 because 65*65 equals 4225.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 764: : 0it [02:04, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 59*73=? The answer is 4367 because 59*73 equals 4367.\n",
      "Expected Answer: The answer is 4307 because 59*73 equals 4307.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 768: : 0it [02:04, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 44*x=2904,x=? The answer is 61 because 2904/44 equals 61.\n",
      "Expected Answer: The answer is 66 because 2904/44 equals 66.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 774: : 0it [02:05, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 88*87=? The answer is 7416 because 88*87 equals 7416.\n",
      "Expected Answer: The answer is 7656 because 88*87 equals 7656.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 780: : 0it [02:06, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5824/x=64,x=? The answer is 86 because 5824/64 equals 86.\n",
      "Expected Answer: The answer is 91 because 5824/64 equals 91.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 793: : 0it [02:09, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/18=78,x=? The answer is 1384 because 78*18 equals 1384.\n",
      "Expected Answer: The answer is 1404 because 78*18 equals 1404.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 795: : 0it [02:09, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/32=83,x=? The answer is 2636 because 83*32 equals 2636.\n",
      "Expected Answer: The answer is 2656 because 83*32 equals 2656.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 802: : 0it [02:10, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/43=19,x=? The answer is 897 because 19*43 equals 897.\n",
      "Expected Answer: The answer is 817 because 19*43 equals 817.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 806: : 0it [02:11, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 3075/x=75,x=? The answer is 167 because 13075/75 equals 167.\n",
      "Expected Answer: The answer is 41 because 3075/75 equals 41.\n",
      "Incorrect\n",
      "Response: x/85=48,x=? The answer is 4180 because 48*85 equals 4180.\n",
      "Expected Answer: The answer is 4080 because 48*85 equals 4080.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 809: : 0it [02:11, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/83=31,x=? The answer is 2693 because 31*83 equals 2693.\n",
      "Expected Answer: The answer is 2573 because 31*83 equals 2573.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 826: : 0it [02:14, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 68*x=2856,x=? The answer is 47 because 2856/68 equals 47.\n",
      "Expected Answer: The answer is 42 because 2856/68 equals 42.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 835: : 0it [02:16, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 76*73=? The answer is 5488 because 76*73 equals 5488.\n",
      "Expected Answer: The answer is 5548 because 76*73 equals 5548.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 838: : 0it [02:16, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 2392/x=52,x=? The answer is 51 because 2392/52 equals 51.\n",
      "Expected Answer: The answer is 46 because 2392/52 equals 46.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 844: : 0it [02:17, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 8*x=584,x=? The answer is 78 because 584/8 equals 78.\n",
      "Expected Answer: The answer is 73 because 584/8 equals 73.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 858: : 0it [02:19, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 56*x=2296,x=? The answer is 46 because 2296/56 equals 46.\n",
      "Expected Answer: The answer is 41 because 2296/56 equals 41.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 869: : 0it [02:21, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x*23=2116,x=? The answer is 82 because 2116/23 equals 82.\n",
      "Expected Answer: The answer is 92 because 2116/23 equals 92.\n",
      "Incorrect\n",
      "Response: x*36=1944,x=? The answer is 59 because 1944/36 equals 59.\n",
      "Expected Answer: The answer is 54 because 1944/36 equals 54.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 878: : 0it [02:23, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/41=81,x=? The answer is 3221 because 81*41 equals 3221.\n",
      "Expected Answer: The answer is 3321 because 81*41 equals 3321.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 881: : 0it [02:23, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/45=31,x=? The answer is 1295 because 31*45 equals 1295.\n",
      "Expected Answer: The answer is 1395 because 31*45 equals 1395.\n",
      "Incorrect\n",
      "Response: x/41=37,x=? The answer is 1497 because 37*41 equals 1497.\n",
      "Expected Answer: The answer is 1517 because 37*41 equals 1517.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 109: : 0it [02:24, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 64*x=5376,x=? The answer is 89 because 5376/64 equals 89.\n",
      "Expected Answer: The answer is 84 because 5376/64 equals 84.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 891: : 0it [02:25, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x*36=2736,x=? The answer is 71 because 2736/36 equals 71.\n",
      "Expected Answer: The answer is 76 because 2736/36 equals 76.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 893: : 0it [02:25, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 4128/96=? The answer is 48 because 4128/96 equals 48.\n",
      "Expected Answer: The answer is 43 because 4128/96 equals 43.\n",
      "Incorrect\n",
      "Response: 4230/x=90,x=? The answer is 157 because 14230/90 equals 157.\n",
      "Expected Answer: The answer is 47 because 4230/90 equals 47.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 900: : 0it [02:26, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 49*67=? The answer is 3243 because 49*67 equals 3243.\n",
      "Expected Answer: The answer is 3283 because 49*67 equals 3283.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 905: : 0it [02:27, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/31=44,x=? The answer is 1484 because 44*31 equals 1484.\n",
      "Expected Answer: The answer is 1364 because 44*31 equals 1364.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 938: : 0it [02:33, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 356/4=? The answer is 84 because 356/4 equals 84.\n",
      "Expected Answer: The answer is 89 because 356/4 equals 89.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 946: : 0it [02:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 5976/72=? The answer is 88 because 5976/72 equals 88.\n",
      "Expected Answer: The answer is 83 because 5976/72 equals 83.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 952: : 0it [02:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 2280/x=76,x=? The answer is 160 because 12280/76 equals 160.\n",
      "Expected Answer: The answer is 30 because 2280/76 equals 30.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 967: : 0it [02:37, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 49*71=? The answer is 3579 because 49*71 equals 3579.\n",
      "Expected Answer: The answer is 3479 because 49*71 equals 3479.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 978: : 0it [02:39, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 3496/38=? The answer is 82 because 3496/38 equals 82.\n",
      "Expected Answer: The answer is 92 because 3496/38 equals 92.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 981: : 0it [02:40, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 27*63=? The answer is 1781 because 27*63 equals 1781.\n",
      "Expected Answer: The answer is 1701 because 27*63 equals 1701.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 983: : 0it [02:40, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: x/52=23,x=? The answer is 1216 because 23*52 equals 1216.\n",
      "Expected Answer: The answer is 1196 because 23*52 equals 1196.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 986: : 0it [02:40, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 624/78=? The answer is 7 because 624/78 equals 7.\n",
      "Expected Answer: The answer is 8 because 624/78 equals 8.\n",
      "Incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt no. 999: : 0it [02:42, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Correct Answers: 889 out of 1000\n"
     ]
    }
   ],
   "source": [
    "# Script to do verification\n",
    "test_set = []\n",
    "answers = []\n",
    "valueLimit = 100\n",
    "\n",
    "# Automating test set generation, and corresponding answers for verification\n",
    "def generate_test_problems(num_problems):\n",
    "    for _ in range(num_problems):\n",
    "        qntype = random.randint(1, 2) # 1: arithmetic, 2: one-step\n",
    "\n",
    "        if qntype == 1: # arithmetic\n",
    "            operation = random.choice(['+', '-', '*', '/'])\n",
    "            if operation == '+':\n",
    "                a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "                test_set.append(f\"{a}+{b}=?\")\n",
    "                answers.append(f\"The answer is {a + b} because {a}+{b} equals {a + b}.\")\n",
    "            elif operation == '-':\n",
    "                a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "                test_set.append(f\"{a}-{b}=?\")\n",
    "                answers.append(f\"The answer is {a - b} because {a}-{b} equals {a - b}.\")\n",
    "            elif operation == '*':  # multiplication\n",
    "                a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "                test_set.append(f\"{a}*{b}=?\")\n",
    "                answers.append(f\"The answer is {a * b} because {a}*{b} equals {a * b}.\")\n",
    "            else:  # division\n",
    "                b = random.randint(1, valueLimit)\n",
    "                answer = random.randint(0, valueLimit)\n",
    "                a = b * answer  # Ensure a is divisible by b\n",
    "                test_set.append(f\"{a}/{b}=?\")\n",
    "                answers.append(f\"The answer is {answer} because {a}/{b} equals {answer}.\")\n",
    "        elif qntype == 2: # one-step equations\n",
    "            positiontype = random.choice(['x_first', 'x_second'])\n",
    "            operation = random.choice(['add', 'subtract', 'multiply', 'divide'])\n",
    "            if operation == 'add':\n",
    "                a,b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "                if positiontype == 'x_first':\n",
    "                    test_set.append(f\"x+{b}={a},x=?\")\n",
    "                    answers.append(f\"The answer is {a - b} because {a}-{b} equals {a - b}.\")\n",
    "                else:\n",
    "                    test_set.append(f\"{b}+x={a},x=?\")\n",
    "                    answers.append(f\"The answer is {a - b} because {a}-{b} equals {a - b}.\")\n",
    "            elif operation == 'subtract':\n",
    "                a, b = random.randint(0, valueLimit), random.randint(0, valueLimit)\n",
    "                if positiontype == 'x_first':\n",
    "                    test_set.append(f\"x-{a}={b},x=?\")\n",
    "                    answers.append(f\"The answer is {b + a} because {b}+{a} equals {b + a}.\")\n",
    "                else:\n",
    "                    test_set.append(f\"{a}-x={b},x=?\")\n",
    "                    answers.append(f\"The answer is {a - b} because {a}-{b} equals {a - b}.\")\n",
    "            elif operation == 'multiply':\n",
    "                a = random.randint(1, valueLimit)\n",
    "                x = random.randint(0, valueLimit)\n",
    "                b = a * x\n",
    "                if positiontype == 'x_first':\n",
    "                    test_set.append(f\"x*{a}={b},x=?\")\n",
    "                    answers.append(f\"The answer is {x} because {b}/{a} equals {x}.\")\n",
    "                else:\n",
    "                    test_set.append(f\"{a}*x={b},x=?\")\n",
    "                    answers.append(f\"The answer is {x} because {b}/{a} equals {x}.\")\n",
    "            else: # Divide\n",
    "                a = random.randint(0, valueLimit)\n",
    "                b = random.randint(1, valueLimit)\n",
    "                if positiontype == 'x_first':\n",
    "                    test_set.append(f\"x/{a}={b},x=?\")\n",
    "                    answers.append(f\"The answer is {b * a} because {b}*{a} equals {b * a}.\")\n",
    "                else:\n",
    "                    b = random.randint(0, valueLimit)\n",
    "                    x = random.randint(1, valueLimit)\n",
    "                    a = b * x\n",
    "                    test_set.append(f\"{a}/x={b},x=?\")\n",
    "                    answers.append(f\"The answer is {x} because {a}/{b} equals {x}.\")\n",
    "\n",
    "test_number = 1000\n",
    "generate_test_problems(test_number)\n",
    "count = 0\n",
    "\n",
    "ckpt_path = \"./dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).to(device)\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test the model\n",
    "gpt.eval()\n",
    "\n",
    "# Making sure gradients will not be computed and updated\n",
    "pbar = tqdm(get_batches(lines, batch_size))\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "        \n",
    "        # Generate response using the fine-tuned model\n",
    "        # Note: generate() returns (generated_sequence, hidden_states)\n",
    "        generated_seq, _ = gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        \n",
    "        # Extract the generated sequence properly\n",
    "        generated_ids = generated_seq[0].cpu().tolist()  # Move to CPU and convert to list\n",
    "            \n",
    "        response = decode(generated_ids)\n",
    "        # Tally correctness\n",
    "        index = test_set.index(prompt)\n",
    "        # Applying verification on strings\n",
    "        if answers[index] in response:\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"Response: {response}\")\n",
    "            print(f\"Expected Answer: {answers[index]}\")\n",
    "            print(\"Incorrect\")\n",
    "        pbar.set_description(\"Prompt no. \" + str(index))\n",
    "\n",
    "# Printing number of correct answers versus total\n",
    "print(f\"\\nTotal Correct Answers: {count} out of {test_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af49f7-b8c7-46ea-b1ec-44144a793647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
